{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10f6da-f29b-45bd-bc46-8c7580dd92a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEP LEARNING\n",
    "have 3 layers\n",
    "1.input layer\n",
    "2.middle layer\n",
    "3.output layer\n",
    "(have activation functions in hiddden layers) (eg: softmax , ReLU (Rectified Linear Unit))\n",
    "having layers of interconnected neurons\n",
    "\n",
    "\n",
    "Convolutional neural networks(CNN)(for images)\n",
    "artifical neural networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72babbce-4bc4-45e1-a2fc-eb54d61d1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEURAL NETWORKS\n",
    "\n",
    "CLASSSES\n",
    "\n",
    "1.Feedforward Neural Network (FFNN)  =Multilayer Perceptron (MLP) (for supervised learning)\n",
    "FFNN moves in one direction (from input to hidden to output layer) also called forward pass\n",
    "can have linear and non linear combination\n",
    "a.linear combination (weighed multiply with input and then sum) (y=mx+c)\n",
    "\n",
    "#ACTIVATION FUNCTION  a = f(z)\n",
    "activation function introduces non linearity in linear combination\n",
    "b.non linear combination \n",
    "activation function finally pass value to output layer\n",
    "then final layer will do prediction from that value\n",
    "\n",
    "non linear activation function is used for multiple layer neural networks\n",
    "e.g: sigmoid function (for classification) (range from 0 to 1)\n",
    "    tangent function is also used for (range from -1 to 1) (better than sigmoid)\n",
    "    reLU (mostly used) (most simple) (most effient)(range from 0 to infinity)\n",
    "\n",
    "#BACK PROPAGATION\n",
    "use gradient decent to minimize loss function and maximize accuracy\n",
    "STEPS:\n",
    "1.checks loss function (cross entropy for classification) (in output layer)\n",
    "2.then back propagate , then updates weights and bias using gradient decent (in middle layer)\n",
    "(commanly used loss function cross entropy loss for classification problems) (gives palenty for incorrect predictions)\n",
    "3.computitional graph\n",
    "\n",
    "Common Problems with Gradient Descent\n",
    "\n",
    "1.Vanishing Gradient\n",
    "(if value of gradient is very small , learning will be very minimum) derivative will move towards zero\n",
    "\n",
    "2. Exploding Gradient\n",
    "(if value of gradient is very large , learning will be very minimum) derivative will move towards one\n",
    "\n",
    "#overfitting problem\n",
    "Increase Training Data\n",
    "Data Augmentation\n",
    "L1/L2 Regularization\n",
    "Dropout\n",
    "Early Stopping\n",
    "Model Simplification\n",
    "Batch Normalization\n",
    "Cross-Validation\n",
    "Transfer Learning\n",
    "Noise Injection\n",
    "Ensemble Methods\n",
    "Pruning\n",
    "Learning Rate Scheduling\n",
    "\n",
    "#underfitting problem\n",
    "Increase Model Complexity\n",
    "Train for More Epochs\n",
    "Use Better Feature Representations\n",
    "Reduce Regularization\n",
    "Lower Dropout Rate\n",
    "Improve Data Quality\n",
    "Remove Early Stopping\n",
    "Optimize Learning Rate\n",
    "Use Pretrained Layers\n",
    "Add More Relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea4f62f-2d9f-41d8-b9c1-da7da0c905cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Handwritten Digit Classification using Feedforward Neural Network on MNIST Dataset# Import libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Handwritten Digit Classification using Feedforward Neural Network on MNIST Dataset\n",
    "# Import libraries\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train / 255.0   # Normalize pixel values to [0, 1]\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = to_categorical(y_train)  # One-hot encode labels\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),        # Flatten input image\n",
    "    Dense(128, activation='relu'),        # First hidden layer\n",
    "    Dense(64, activation='relu'),         # Second hidden layer\n",
    "    Dense(10, activation='softmax')       # Output layer (10 classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f268bcd-ac37-4d7c-8d7c-e76e24145f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load MNIST\u001b[39;00m\n\u001b[0;32m      5\u001b[0m (X_train, y_train), _ \u001b[38;5;241m=\u001b[39m mnist\u001b[38;5;241m.\u001b[39mload_data()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Visualizing Sample Handwritten Digits from the MNIST Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST\n",
    "(X_train, y_train), _ = mnist.load_data()\n",
    "\n",
    "# Plot first 9 images\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346e309-7528-4639-9508-3c6724690e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
